# P√°gina de Monitoramento de Scrapers

P√°gina frontend criada para visualizar a execu√ß√£o e status dos scrapers de dados, com gr√°ficos interativos usando ApexCharts.

## üéØ Funcionalidades

### Visualiza√ß√µes
- **Execu√ß√µes por Dia**: Gr√°fico de linha mostrando execu√ß√µes bem-sucedidas vs com erro
- **Distribui√ß√£o por Status**: Gr√°fico de pizza (donut) mostrando propor√ß√£o de sucesso/erro/executando
- **Execu√ß√µes por Servi√ßo**: Gr√°fico de barras horizontais mostrando volume por scraper
- **Tabela de Scrapers Funcionando**: Lista de scrapers com dados recentes

### Filtros
- √öltimos 7 dias
- √öltimos 15 dias
- √öltimos 30 dias

### Cards de Resumo
- Total de Execu√ß√µes
- Scrapers Ativos
- Scrapers Funcionando (com dados no per√≠odo)
- Taxa de Sucesso (%)

## üöÄ Como Testar

### 1. Popular dados de exemplo no Azure Databricks

```bash
cd api
export $(cat .env | xargs)
node scripts/populate-scrapers-data.js
```

Este script ir√° inserir ~90 registros dos √∫ltimos 15 dias com dados simulados de 6 scrapers diferentes.

### 2. Iniciar o backend (se n√£o estiver rodando)

```bash
cd api
pnpm run start:dev
```

### 3. Iniciar o frontend (se n√£o estiver rodando)

```bash
cd frontend
pnpm run dev
```

### 4. Acessar a p√°gina

1. Fa√ßa login com: `conjo` / `admin123`
2. Clique no menu **"Scrapers"**
3. Visualize os gr√°ficos e dados

## üìä Estrutura dos Dados

### Tabela Azure: `default.tb_health_scrappers`

```sql
- id: BIGINT (identity)
- service: STRING (nome do scraper)
- total_registros: BIGINT (quantidade extra√≠da)
- execution_time: BIGINT (tempo em segundos)
- state: STRING (UF onde executou)
- status: STRING (success/error/running)
- error_message: STRING (mensagem de erro, se houver)
- created_at: TIMESTAMP
- updated_at: TIMESTAMP
```

## üîå Endpoints da API

### GET /scrapers/health
Lista execu√ß√µes com filtros opcionais:
- `service` - Filtrar por nome do scraper
- `state` - Filtrar por UF
- `status` - Filtrar por status (success/error/running)
- `startDate` - Data inicial (ISO 8601)
- `endDate` - Data final (ISO 8601)
- `limit` - Limitar resultados (padr√£o: 100)

### GET /scrapers/health/stats
Retorna estat√≠sticas agregadas:
- Execu√ß√µes por servi√ßo e status
- Tempo m√©dio de execu√ß√£o
- √öltima execu√ß√£o

### POST /scrapers/health
Receber status de execu√ß√£o do scraper:
```json
{
  "service": "scraper_sp_leis",
  "total_registros": 1523,
  "execution_time": 127,
  "state": "SP",
  "status": "success"
}
```

## üé® Componentes Criados

### Frontend
- `/src/pages/ScrapersPage.tsx` - P√°gina principal
- `/src/services/scrapers.service.ts` - Service para API
- Atualizado `/src/components/Layout.tsx` - Menu com link Scrapers
- Atualizado `/src/App.tsx` - Rota `/scrapers`

### Backend
- `/src/scrapers/scrapers.module.ts` - M√≥dulo NestJS
- `/src/scrapers/scrapers.controller.ts` - Controller
- `/src/scrapers/scrapers.service.ts` - Service
- `/src/scrapers/dto/scraper-health.dto.ts` - DTOs
- Atualizado `/src/database/database.service.ts` - M√©todos queryScrapers/executeScrapers

### Scripts
- `/scripts/create-health-scrappers-table.js` - Criar tabela no Azure
- `/scripts/populate-scrapers-data.js` - Popular dados de exemplo
- `/scripts/test-scrapers-endpoint.js` - Testar endpoints

## üìù Notas

- Todos os endpoints est√£o protegidos com JWT (mesmo token usado nos outros endpoints)
- Scrapers s√£o considerados "funcionando" quando t√™m status=success no per√≠odo
- A p√°gina atualiza estat√≠sticas automaticamente a cada 30 segundos
- Dados s√£o carregados do Azure Databricks em tempo real
